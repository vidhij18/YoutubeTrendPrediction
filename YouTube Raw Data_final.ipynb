{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dce6c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apiclient.discovery import build\n",
    "\n",
    "def build_service(filename):\n",
    "    with open(filename) as f:\n",
    "        key = f.readline()\n",
    "\n",
    "    YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "    YOUTUBE_API_VERSION = \"v3\"\n",
    "    return build(YOUTUBE_API_SERVICE_NAME,\n",
    "                 YOUTUBE_API_VERSION,\n",
    "                 developerKey=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5a597eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade google-api-python-client\n",
    "apikey = ''\n",
    "service = build_service('apikey.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31dd3de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59ef0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import urllib.request\n",
    "# import string\n",
    "# import random\n",
    "\n",
    "# count = 50\n",
    "\n",
    "# random = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(3))\n",
    "# print(random)\n",
    "# random_videoIds = set()\n",
    "# urlData = \"https://www.googleapis.com/youtube/v3/search?key={}&maxResults={}&part=snippet&type=video&q={}\".format(apikey,count,random)\n",
    "# webURL = urllib.request.urlopen(urlData)\n",
    "# data = webURL.read()\n",
    "# encoding = webURL.info().get_content_charset('utf-8')\n",
    "# results = json.loads(data.decode(encoding))\n",
    "# print(len(random_videoIds))\n",
    "\n",
    "# for data in results['items']:\n",
    "#     videoId = (data['id']['videoId'])\n",
    "#     random_videoIds.add(videoId)\n",
    "    \n",
    "# print(len(random_videoIds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae7a757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get random youtube video_id\n",
    "def get_random_video_id(i=1):\n",
    "    import json\n",
    "    import urllib.request\n",
    "    import string\n",
    "    import random\n",
    "\n",
    "    count = 50\n",
    "    # API_KEY = 'your_key'\n",
    "#     random = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(3))\n",
    "    random_videoIds = set()\n",
    "    \n",
    "    try:\n",
    "        while(len(random_videoIds) <= 10000):\n",
    "            random_key = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(3))\n",
    "            urlData = \"https://www.googleapis.com/youtube/v3/search?key={}&maxResults={}&part=snippet&type=video&q={}\".format(apikey,count,random_key)\n",
    "            webURL = urllib.request.urlopen(urlData)\n",
    "            data = webURL.read()\n",
    "            encoding = webURL.info().get_content_charset('utf-8')\n",
    "            results = json.loads(data.decode(encoding))\n",
    "            print(len(random_videoIds))\n",
    "\n",
    "            for data in results['items']:\n",
    "                videoId = (data['id']['videoId'])\n",
    "                random_videoIds.add(videoId)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        textfile = open(\"random_videos\"+str(i)+\".txt\", \"w\")\n",
    "        for element in random_videoIds:\n",
    "            textfile.write(element + \"\\n\")\n",
    "        textfile.close()\n",
    "        return random_videoIds\n",
    "\n",
    "    textfile = open(\"random_videos\"+str(i)+\".txt\", \"w\")\n",
    "    for element in random_videoIds:\n",
    "        textfile.write(element + \"\\n\")\n",
    "    textfile.close()\n",
    "    return random_videoIds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7418d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_videos = get_random_video_id(4)\n",
    "print(len(random_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d94f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_metadata(val=1):\n",
    "    \n",
    "    my_file = open(\"random_videos\"+str(val)+\".txt\", \"r\")\n",
    "    content = my_file.read()\n",
    "    videoIdList = content.splitlines()\n",
    "    my_file.close()\n",
    "\n",
    "    #output list required\n",
    "    video_id = [] #got\n",
    "    title = [] #got\n",
    "    publishedAt = [] #got\n",
    "    channelId = [] #got\n",
    "    channelTitle = [] #got\n",
    "    categoryId = [] #got\n",
    "    trending_date = [] #none\n",
    "    tags = [] #got\n",
    "    view_count = [] #got\n",
    "    likes = [] #got\n",
    "    dislikes = []\n",
    "    comment_count = [] #got\n",
    "    thumbnail_link = [] #none\n",
    "    comments_disabled = [] #none\n",
    "    ratings_disabled = [] #none\n",
    "    description = [] #got\n",
    "\n",
    "\n",
    "    for i in range(0, len(videoIdList)):\n",
    "        try:\n",
    "            response = service.videos().list(\n",
    "                        part=\"statistics,snippet\",\n",
    "                        id=videoIdList[i]\n",
    "                    ).execute()             \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Failed on this video, trying next...\", videoIdList[i])\n",
    "            continue\n",
    "\n",
    "\n",
    "        for item in response['items']:\n",
    "    #         print(item)\n",
    "\n",
    "            try:\n",
    "                likes.append(item['statistics']['likeCount'])\n",
    "            except:\n",
    "                likes.append(None)\n",
    "\n",
    "            try:\n",
    "                video_id.append(item['id'])\n",
    "            except:\n",
    "                video_id.append(None)\n",
    "\n",
    "            try:\n",
    "                view_count.append(item['statistics']['viewCount'])\n",
    "            except:\n",
    "                view_count.append(None)\n",
    "\n",
    "            try:\n",
    "                publishedAt.append(item['snippet']['publishedAt'])\n",
    "            except:\n",
    "                publishedAt.append(None)\n",
    "\n",
    "            try:\n",
    "                channelId.append(item['snippet']['channelId'])\n",
    "            except:\n",
    "                channelId.append(None)\n",
    "\n",
    "            try:\n",
    "                categoryId.append(item['snippet']['categoryId'])\n",
    "            except:\n",
    "                categoryId.append(None)\n",
    "\n",
    "            try:\n",
    "                channelTitle.append(item['snippet']['channelTitle'])\n",
    "            except:\n",
    "                channelTitle.append(None)\n",
    "\n",
    "            try:\n",
    "                title.append(item['snippet']['title'])\n",
    "            except:\n",
    "                title.append(None)\n",
    "\n",
    "            try:\n",
    "                description.append(item['snippet']['description'])\n",
    "            except:\n",
    "                description.append(None)\n",
    "\n",
    "            try:\n",
    "                tags.append(item['snippet']['tags'] )\n",
    "            except:\n",
    "                tags.append(None)\n",
    "\n",
    "            try:\n",
    "                comment_count.append(item['statistics']['commentCount'] or None)\n",
    "            except:\n",
    "                comment_count.append(None)\n",
    "\n",
    "\n",
    "    trending_date = [None] * len(likes)\n",
    "    dislikes = [None] * len(likes)\n",
    "    thumbnail_link= [None] * len(likes)\n",
    "    comments_disabled = [None] * len(likes)\n",
    "    ratings_disabled = [None] * len(likes)\n",
    "    tags = [None] * len(likes)\n",
    "\n",
    "#     print(len(likes))\n",
    "#     print(len(dislikes))\n",
    "#     print(len(thumbnail_link))\n",
    "#     print(len(view_count))\n",
    "#     print(len(video_id))\n",
    "#     print(len(publishedAt))\n",
    "#     print(len(channelId))\n",
    "#     print(len(channelTitle))\n",
    "#     print(len(categoryId))\n",
    "#     print(len(title))\n",
    "#     print(len(description))\n",
    "#     print(len(tags))\n",
    "#     print(len(trending_date))\n",
    "#     print(len(comments_disabled))\n",
    "#     print(len(ratings_disabled))\n",
    "\n",
    "\n",
    "    non_trending_data = pd.DataFrame({'video_id': video_id,'title': title,'publishedAt': publishedAt,'channelId': channelId,\n",
    "                                      'channelTitle': channelTitle,'categoryId' : categoryId, 'trending_date': trending_date,\n",
    "                                      'tags': tags,'view_count': view_count,'likes': likes,'dislikes':dislikes,\n",
    "                                      'comment_count': comment_count, 'thumbnail_link': thumbnail_link,\n",
    "                                      'comments_disabled': comments_disabled,'ratings_disabled':ratings_disabled,\n",
    "                                      'description':description\n",
    "                                     })\n",
    "    if not non_trending_data.empty:\n",
    "        finaldf = non_trending_data.drop_duplicates().dropna(axis = 0, how = 'all', inplace = False)\n",
    "        finaldf.shape\n",
    "        finaldf.head()\n",
    "        finaldf.to_csv(r\"./NonTrendingData\"+str(val)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c2fba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_video_metadata(1)\n",
    "get_video_metadata(2)\n",
    "# get_video_metadata(3)\n",
    "# get_video_metadata(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f3131f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_trending_data = pd.DataFrame({'video_id': video_id,'title': title,'publishedAt': publishedAt,'channelId': channelId,\n",
    "#                                       'channelTitle': channelTitle,'categoryId' : categoryId, 'trending_date': trending_date,\n",
    "#                                       'tags': tags,'view_count': view_count,'likes': likes,'dislikes':dislikes,\n",
    "#                                       'comment_count': comment_count, 'thumbnail_link': thumbnail_link,\n",
    "#                                       'comments_disabled': comments_disabled,'ratings_disabled':ratings_disabled,\n",
    "#                                       'description':description\n",
    "#                                      })\n",
    "# if not non_trending_data.empty:\n",
    "#         finaldf = non_trending_data.drop_duplicates().dropna(axis = 0, how = 'all', inplace = False)\n",
    "#         finaldf.shape\n",
    "#         finaldf.head()\n",
    "#         finaldf.to_csv(r\"./NonTrendingData\"+str(10)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cf4b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_file = open(\"random_videos9.txt\", \"r\")\n",
    "# content = my_file.read()\n",
    "# videoIdList = content.splitlines()\n",
    "# my_file.close()\n",
    "\n",
    "# response = service.videos().list(\n",
    "#                 part=\"statistics,snippet\",\n",
    "#                 id=videoIdList[0]\n",
    "#             ).execute() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e491019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in response['items']:\n",
    "#     print(item)\n",
    "    \n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "341959e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FINALData1.csv', 'FINALData2.csv']\n"
     ]
    }
   ],
   "source": [
    "# !pip install glob\n",
    "import glob\n",
    "\n",
    "csvFiles = glob.glob('FINALData*.csv')\n",
    "print(csvFiles)\n",
    "finaldf = pd.DataFrame(columns = ['video_id','title','publishedAt','channelId','channelTitle','categoryId', 'trending_date',\n",
    "                                      'tags','view_count','likes','dislikes','comment_count', 'thumbnail_link',\n",
    "                                      'comments_disabled','ratings_disabled','description'\n",
    "                                 ])\n",
    "\n",
    "#pandas read csv\n",
    "#union csv\n",
    "for file in csvFiles:\n",
    "    tempdf = pd.read_csv(file)\n",
    "    finaldf = pd.concat([finaldf, tempdf])\n",
    "\n",
    "#drop duplicates\n",
    "#write CSV\n",
    "finaldf.drop_duplicates().to_csv(r\"./ULTIMATEFINALData.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
